/*
 * SOP2
 */

DEFINST(S_ADD_U32,
	" s_add_u32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	0,
	4,
	0
)

DEFINST(S_ADD_I32,
	" s_add_i32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	2,
	4,
	0
)

DEFINST(S_SUB_I32,
	" s_sub_i32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	3,
	4,
	0
)

DEFINST(S_MIN_U32,
	" s_min_u32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	7,
	4,
	0
)

DEFINST(S_MAX_I32,
	" s_max_i32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	8,
	4,
	0
)

DEFINST(S_MAX_U32,
	" s_max_u32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	9,
	4,
	0
)

DEFINST(S_CSELECT_B32,
	" s_cselect_b32  %SDST, %SSRC0, %SSRC1",
	SOP2,
	10,
	4,
	0
)

DEFINST(S_AND_B32,
	" s_and_b32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	14,
	4,
	0
)

DEFINST(S_AND_B64,
	" s_and_b64     %64_SDST, %64_SSRC0, %64_SSRC1",
	SOP2,
	15,
	4,
	0
)

DEFINST(S_OR_B32,
	" s_or_b32      %SDST, %SSRC0, %SSRC1",
	SOP2,
	16,
	4,
	0
)

DEFINST(S_OR_B64,
	" s_or_b64      %64_SDST, %64_SSRC0, %64_SSRC1",
	SOP2,
	17,
	4,
	0
)

DEFINST(S_XOR_B64,
	" s_xor_b64     %64_SDST, %64_SSRC0, %64_SSRC1",
	SOP2,
	19,
	4,
	0
)

DEFINST(S_ANDN2_B64,
	" s_andn2_b64   %64_SDST, %64_SSRC0, %64_SSRC1",
	SOP2,
	21,
	4,
	0
)

DEFINST(S_NAND_B64,
	" s_nand_b64    %64_SDST, %64_SSRC0, %64_SSRC1",
	SOP2,
	25,
	4,
	0
)

DEFINST(S_LSHL_B32,
	" s_lshl_b32    %SDST, %SSRC0, %SSRC1",
	SOP2,
	30,
	4,
	0
)

DEFINST(S_LSHR_B32,
	" s_lshr_b32    %SDST, %SSRC0, %SSRC1",
	SOP2,
	32,
	4,
	0
)

DEFINST(S_ASHR_I32,
	" s_ashr_i32    %SDST, %SSRC0, %SSRC1",
	SOP2,
	34,
	4,
	0
)

DEFINST(S_MUL_I32,
	" s_mul_i32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	38,
	4,
	0
)

DEFINST(S_BFE_I32,
	" s_bfe_i32     %SDST, %SSRC0, %SSRC1",
	SOP2,
	40,
	4,
	0
)


/*
 * SOPK
 */

DEFINST(S_MOVK_I32,
	" s_movk_i32    %SDST, %SIMM16",
	SOPK,
	0,
	4,
	0
)

DEFINST(S_CMPK_LE_U32,
	" s_cmpk_le_u32    %SDST, %SIMM16",
	SOPK,
	14,
	4,
	0
)

DEFINST(S_ADDK_I32,
	" s_addk_i32    %SDST, %SIMM16",
	SOPK,
	15,
	4,
	0
)

DEFINST(S_MULK_I32,
	" s_mulk_i32    %SDST, %SIMM16",
	SOPK,
	16,
	4,
	0
)

/*
 * SOP1
 */

DEFINST(S_MOV_B32,
	" s_mov_b32     %SDST, %SSRC0",
	SOP1,
	3,
	4,
	0
)

DEFINST(S_MOV_B64,
	" s_mov_b64     %64_SDST, %64_SSRC0",
	SOP1,
	4,
	4,
	0
)

DEFINST(S_NOT_B32,
	" s_not_b32     %SDST, %SSRC0",
	SOP1,
	7,
	4,
	0
)

DEFINST(S_SWAPPC_B64,
	" s_swappc_b64  %64_SDST, %64_SSRC0",
	SOP1,
	33,
	4,
	0
)

DEFINST(S_AND_SAVEEXEC_B64,
	" s_and_saveexec_b64  %64_SDST, %64_SSRC0",
	SOP1,
	36,
	4,
	0
)

/*
 * SOPC
 */

DEFINST(S_CMP_EQ_I32,
	" s_cmp_eq_i32  %SSRC0, %SSRC1",
	SOPC,
	0,
	4,
	0
)

DEFINST(S_CMP_GT_I32,
	" s_cmp_gt_i32  %SSRC0, %SSRC1",
	SOPC,
	2,
	4,
	0
)

DEFINST(S_CMP_GE_I32,
	" s_cmp_ge_i32  %SSRC0, %SSRC1",
	SOPC,
	3,
	4,
	0
)

DEFINST(S_CMP_LT_I32,
	" s_cmp_lt_i32  %SSRC0, %SSRC1",
	SOPC,
	4,
	4,
	0
)

DEFINST(S_CMP_LE_I32,
	" s_cmp_le_i32  %SSRC0, %SSRC1",
	SOPC,
	5,
	4,
	0
)

DEFINST(S_CMP_GT_U32,
	" s_cmp_gt_u32  %SSRC0, %SSRC1",
	SOPC,
	8,
	4,
	0
)

DEFINST(S_CMP_GE_U32,
	" s_cmp_ge_u32  %SSRC0, %SSRC1",
	SOPC,
	9,
	4,
	0
)

DEFINST(S_CMP_LE_U32,
	" s_cmp_le_u32  %SSRC0, %SSRC1",
	SOPC,
	11,
	4,
	0
)

/*
 * SOPP
 */

DEFINST(S_ENDPGM,
	" s_endpgm",
	SOPP,
	1,
	4,
	0
)

DEFINST(S_BRANCH,
	" s_branch      %LABEL",
	SOPP,
	2,
	4,
	0
)

DEFINST(S_CBRANCH_SCC0,
	" s_cbranch_scc0  %LABEL",
	SOPP,
	4,
	4,
	0
)

DEFINST(S_CBRANCH_SCC1,
	" s_cbranch_scc1  %LABEL",
	SOPP,
	5,
	4,
	0
)

DEFINST(S_CBRANCH_VCCZ,
	" s_cbranch_vccz  %LABEL",
	SOPP,
	6,
	4,
	0
)

DEFINST(S_CBRANCH_VCCNZ,
	" s_cbranch_vccnz  %LABEL",
	SOPP,
	7,
	4,
	0
)

DEFINST(S_CBRANCH_EXECZ,
	" s_cbranch_execz  %LABEL",
	SOPP,
	8,
	4,
	0
)

DEFINST(S_CBRANCH_EXECNZ,
	" s_cbranch_execnz  %LABEL",
	SOPP,
	9,
	4,
	0
)

DEFINST(S_BARRIER,
	" s_barrier",
	SOPP,
	10,
	4,
	0
)

DEFINST(S_WAITCNT,
	" s_waitcnt     %WAIT_CNT",
	SOPP,
	12,
	4,
	0
)

/*
 * SMRD
 */

DEFINST(S_LOAD_DWORDX2,
	" s_load_dwordx2  %SERIES_SDST, %SERIES_SBASE, %OFFSET",
	SMRD,
	1,
	4,
	0
)

DEFINST(S_LOAD_DWORDX4,
	" s_load_dwordx4  %SERIES_SDST, %SERIES_SBASE, %OFFSET",
	SMRD,
	2,
	4,
	0
)

DEFINST(S_LOAD_DWORDX8,
	" s_load_dwordx8  %SERIES_SDST, %SERIES_SBASE, %OFFSET",
	SMRD,
	3,
	4,
	0
)

DEFINST(S_BUFFER_LOAD_DWORD,
	" s_buffer_load_dword  %SMRD_SDST, %SERIES_SBASE, %OFFSET",
	SMRD, 
	8,
	4,
	0
)

DEFINST(S_BUFFER_LOAD_DWORDX2,
	" s_buffer_load_dwordx2  %SERIES_SDST, %SERIES_SBASE, %OFFSET",
	SMRD,
	9,
	4,
	0
)

DEFINST(S_BUFFER_LOAD_DWORDX4,
	" s_buffer_load_dwordx4  %SERIES_SDST, %SERIES_SBASE, %OFFSET",
	SMRD,
	10,
	4,
	0
)

/*
 * VOP2
 */

DEFINST(V_CNDMASK_B32,
	" v_cndmask_b32  %VDST, %SRC0, %VSRC1, vcc",
	VOP2,
	0,
	4,
	0
)

DEFINST(V_ADD_F32,
	" v_add_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	3,
	4,
	0
)

DEFINST(V_SUB_F32,
	" v_sub_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	4,
	4,
	0
)

DEFINST(V_SUBREV_F32,
	" v_subrev_f32  %VDST, %SRC0, %VSRC1",
	VOP2,
	5,
	4,
	0
)

DEFINST(V_MAC_LEGACY_F32,
	" v_mac_legacy_f32  %VDST, %SRC0, %VSRC1",
	VOP2,
	6,
	4,
	0
)

DEFINST(V_MUL_LEGACY_F32,
	" v_mul_legacy_f32  %VDST, %SRC0, %VSRC1",
	VOP2,
	7,
	4,
	0
)

DEFINST(V_MUL_F32,
	" v_mul_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	8,
	4,
	0
)

DEFINST(V_MUL_I32_I24,
	" v_mul_i32_i24  %VDST, %SRC0, %VSRC1",
	VOP2,
	9,
	4,
	0
)

DEFINST(V_MIN_F32,
	" v_min_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	15,
	4,
	0
)

DEFINST(V_MAX_F32,
	" v_max_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	16,
	4,
	0
)

DEFINST(V_MAX_I32,
	" v_max_i32     %VDST, %SRC0, %VSRC1",
	VOP2,
	18,
	4,
	0
)

DEFINST(V_MIN_U32,
	" v_min_u32     %VDST, %SRC0, %VSRC1",
	VOP2,
	19,
	4,
	0
)

DEFINST(V_MAX_U32,
	" v_max_u32     %VDST, %SRC0, %VSRC1",
	VOP2,
	20,
	4,
	0
)

DEFINST(V_LSHRREV_B32,
	" v_lshrrev_b32  %VDST, %SRC0, %VSRC1",
	VOP2,
	22,
	4,
	0
)

DEFINST(V_ASHRREV_I32,
	" v_ashrrev_i32  %VDST, %SRC0, %VSRC1",
	VOP2,
	24,
	4,
	0
)

DEFINST(V_LSHL_B32,
	" v_lshl_b32    %VDST, %SRC0, %VSRC1",
	VOP2,
	25,
	4,
	0
)

DEFINST(V_LSHLREV_B32,
	" v_lshlrev_b32  %VDST, %SRC0, %VSRC1",
	VOP2,
	26,
	4,
	0
)

DEFINST(V_AND_B32,
	" v_and_b32     %VDST, %SRC0, %VSRC1",
	VOP2,
	27,
	4,
	0
)

DEFINST(V_OR_B32,
	" v_or_b32      %VDST, %SRC0, %VSRC1",
	VOP2,
	28,
	4,
	0
)

DEFINST(V_XOR_B32,
	" v_xor_b32     %VDST, %SRC0, %VSRC1",
	VOP2,
	29,
	4,
	0
)

DEFINST(V_BFM_B32,
	" v_bfm_b32     %VDST, %SRC0, %VSRC1",
	VOP2,
	30,
	4,
	0
)

DEFINST(V_MAC_F32,
	" v_mac_f32     %VDST, %SRC0, %VSRC1",
	VOP2,
	31,
	4,
	0
)

DEFINST(V_MADMK_F32,
	" v_madmk_f32   %VDST, %SRC0, %VOP2_LIT, %VSRC1",
	VOP2,
	32,
	8,
	0
)

DEFINST(V_ADD_I32,
	" v_add_i32     %VDST, vcc, %SRC0, %VSRC1",
	VOP2,
	37,
	4,
	0
)

DEFINST(V_SUB_I32,
	" v_sub_i32     %VDST, vcc, %SRC0, %VSRC1",
	VOP2,
	38,
	4,
	0
)

DEFINST(V_SUBREV_I32,
	" v_subrev_i32  %VDST, vcc, %SRC0, %VSRC1",
	VOP2,
	39,
	4,
	0
)

DEFINST(V_CVT_PKRTZ_F16_F32,
	" v_cvt_pkrtz_f16_f32  %VDST, vcc, %SRC0, %VSRC1",
	VOP2,
	47,
	4,
	0
)

/*
 * VOP1
 */

DEFINST(V_NOP,
	" v_nop",
	VOP1,
	0,
	4,
	0
)

DEFINST(V_MOV_B32,
	" v_mov_b32     %VDST, %SRC0",
	VOP1,
	1,
	4,
	0
)

DEFINST(V_READFIRSTLANE_B32,
	" v_readfirstlane_b32  %SVDST, %SRC0",
	VOP1,
	2,
	4,
	0
)

DEFINST(V_CVT_I32_F64,
	" v_cvt_i32_f64  %64_VDST, %64_SRC0",
	VOP1,
	3,
	4,
	0
)

DEFINST(V_CVT_F64_I32,
	" v_cvt_f64_i32  %64_VDST, %SRC0",
	VOP1,
	4,
	4,
	0
)

DEFINST(V_CVT_F32_I32,
	" v_cvt_f32_i32  %VDST, %SRC0",
	VOP1,
	5,
	4,
	0
)

DEFINST(V_CVT_F32_U32,
	" v_cvt_f32_u32  %VDST, %SRC0",
	VOP1,
	6,
	4,
	0
)

DEFINST(V_CVT_U32_F32,
	" v_cvt_u32_f32  %VDST, %SRC0",
	VOP1,
	7,
	4,
	0
)

DEFINST(V_CVT_I32_F32,
	" v_cvt_i32_f32  %VDST, %SRC0",
	VOP1,
	8,
	4,
	0
)

DEFINST(V_CVT_F32_F64,
	" v_cvt_f32_f64  %VDST, %64_SRC0",
	VOP1,
	15,
	4,
	0
)

DEFINST(V_CVT_F64_F32,
	" v_cvt_f64_f32  %64_VDST, %SRC0",
	VOP1,
	16,
	4,
	0
)

DEFINST(V_CVT_F64_U32,
	" v_cvt_f64_u32  %64_VDST, %64_SRC0",
	VOP1,
	22,
	4,
	0
)

DEFINST(V_TRUNC_F32,
	" v_trunc_f32   %VDST, %SRC0",
	VOP1,
	33,
	4,
	0
)

DEFINST(V_FLOOR_F32,
	" v_floor_f32   %VDST, %SRC0",
	VOP1,
	36,
	4,
	0
)

DEFINST(V_LOG_F32,
	" v_log_f32     %VDST, %SRC0",
	VOP1,
	39,
	4,
	0
)

DEFINST(V_RCP_F32,
	" v_rcp_f32     %VDST, %SRC0",
	VOP1,
	42,
	4,
	0
)

DEFINST(V_RCP_F64,
	" v_rcp_f64     %64_VDST, %64_SRC0",
	VOP1,
	47,
	4,
	0
)

DEFINST(V_RSQ_F64,
	" v_rsq_f64     %64_VDST, %64_SRC0",
	VOP1,
	49,
	4,
	0
)

DEFINST(V_SQRT_F32,
	" v_sqrt_f32    %VDST, %SRC0",
	VOP1,
	51,
	4,
	0
)

DEFINST(V_SIN_F32,
	" v_sin_f32     %VDST, %SRC0",
	VOP1,
	53,
	4,
	0
)

DEFINST(V_COS_F32,
	" v_cos_f32     %VDST, %SRC0",
	VOP1,
	54,
	4,
	0
)

DEFINST(V_NOT_B32,
	" v_not_b32    %VDST, %SRC0",
	VOP1,
	55,
	4,
	0
)

DEFINST(V_FFBH_U32,
	" v_ffbh_u32    %VDST, %SRC0",
	VOP1,
	57,
	4,
	0
)

DEFINST(V_FRACT_F64,
	" v_fract_f64   %VDST, %SRC0 CHECKME",
	VOP1,
	62,
	4,
	0
)

DEFINST(V_MOVRELD_B32,
	" v_movreld_b32  %VDST, %SRC0",
	VOP1,
	66,
	4,
	0
)

DEFINST(V_MOVRELS_B32,
	" v_movrels_b32  %VDST, %SRC0",
	VOP1,
	67,
	4,
	0
)

/* 
 * VOPC 
 */
DEFINST(V_CMP_LT_F32,
	" v_cmp_lt_f32  vcc, %SRC0, %VSRC1",
	VOPC,
	1,
	4,
	0
)

DEFINST(V_CMP_GT_F32,
	" v_cmp_gt_f32  vcc, %SRC0, %VSRC1",
	VOPC,
	4,
	4,
	0
)

DEFINST(V_CMP_GE_F32,
	" v_cmp_ge_f32  vcc, %SRC0, %VSRC1",
	VOPC,
	6,
	4,
	0
)

DEFINST(V_CMP_NGT_F32,
	" v_cmp_ngt_f32  vcc, %SRC0, %VSRC1",
	VOPC,
	11,
	4,
	0
)

DEFINST(V_CMP_NEQ_F32,
	" v_cmp_neq_f32  vcc, %SRC0, %VSRC1",
	VOPC,
	13,
	4,
	0
)

DEFINST(V_CMP_LT_F64,
	" v_cmp_lt_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	33,
	4,
	0
)

DEFINST(V_CMP_EQ_F64,
	" v_cmp_eq_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	34,
	4,
	0
)

DEFINST(V_CMP_LE_F64,
	" v_cmp_le_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	35,
	4,
	0
)

DEFINST(V_CMP_GT_F64,
	" v_cmp_gt_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	36,
	4,
	0
)

DEFINST(V_CMP_NGE_F64,
	" v_cmp_nge_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	41,
	4,
	0
)

DEFINST(V_CMP_NEQ_F64,
	" v_cmp_neq_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	45,
	4,
	0
)

DEFINST(V_CMP_LT_I32,
	" v_cmp_lt_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	129,
	4,
	0
)

DEFINST(V_CMP_EQ_I32,
	" v_cmp_eq_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	130,
	4,
	0
)

DEFINST(V_CMP_LE_I32,
	" v_cmp_le_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	131,
	4,
	0
)

DEFINST(V_CMP_GT_I32,
	" v_cmp_gt_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	132,
	4,
	0
)

DEFINST(V_CMP_NE_I32,
	" v_cmp_ne_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	133,
	4,
	0
)

DEFINST(V_CMP_GE_I32,
	" v_cmp_ge_i32  vcc, %SRC0, %VSRC1",
	VOPC,
	134,
	4,
	0
)

DEFINST(V_CMP_CLASS_F64,
	" v_cmp_class_f64  vcc, %64_SRC0, %64_VSRC1",
	VOPC,
	168,
	4,
	0
)

DEFINST(V_CMP_LT_U32,
	" v_cmp_lt_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	193,
	4,
	0
)

DEFINST(V_CMP_EQ_U32,
	" v_cmp_eq_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	194,
	4,
	0
)

DEFINST(V_CMP_LE_U32,
	" v_cmp_le_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	195,
	4,
	0
)

DEFINST(V_CMP_GT_U32,
	" v_cmp_gt_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	196,
	4,
	0
)

DEFINST(V_CMP_NE_U32,
	" v_cmp_ne_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	197,
	4,
	0
)

DEFINST(V_CMP_GE_U32,
	" v_cmp_ge_u32  vcc, %SRC0, %VSRC1",
	VOPC,
	198,
	4,
	0
)



/*
 * VOP3a 
 */

DEFINST(V_CNDMASK_B32_VOP3a,
	" v_cndmask_b32  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_64_SRC2",
	VOP3a,
	256,
	8,
	0
)

DEFINST(V_ADD_F32_VOP3a,
	" v_add_f32      %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_64_SRC2",
	VOP3a,
	259,
	8,
	0
)

DEFINST(V_SUBREV_F32_VOP3a,
	" v_subrev_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_64_SRC2",
	VOP3a,
	261,
	8,
	0
)

DEFINST(V_MUL_F32_VOP3a,
	" v_mul_f32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	264,
	8,
	0
)

DEFINST(V_MUL_I32_I24_VOP3a,
	" v_mul_i32_i24  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	265,
	8,
	0
)

DEFINST(V_MAX_F32_VOP3a,
	" v_max_f32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	272,
	8,
	0
)

DEFINST(V_MAD_F32,
	" v_mad_f32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	321,
	8,
	0
)

DEFINST(V_MAD_U32_U24,
	" v_mad_u32_u24  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	323,
	8,
	0
)

DEFINST(V_BFE_U32,
	" v_bfe_u32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	328,
	8,
	0
)

DEFINST(V_BFE_I32,
	" v_bfe_i32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	329,
	8,
	0
)

DEFINST(V_BFI_B32,
	" v_bfi_b32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	330,
	8,
	0
)

DEFINST(V_FMA_F32,
	" v_fma_f32     %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	331,
	8,
	0
)
	
DEFINST(V_FMA_F64,
	" v_fma_f64     %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_64_SRC1, %VOP3_64_SRC2",
	VOP3a,
	332,
	8,
	0
)

DEFINST(V_ALIGNBIT_B32,
	" v_alignbit_b32  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	334,
	8,
	0
)

DEFINST(V_DIV_FIXUP_F64,
	" v_div_fixup_f64  %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_64_SRC1, %VOP3_64_SRC2",
	VOP3a,
	352,
	8,
	0
)

DEFINST(V_MIN_F64,
	" v_min_f64    FIXME",
	VOP3a,
	358,
	8,
	0
)

DEFINST(V_MAX_F64,
	" v_max_f64    FIXME",
	VOP3a,
	359,
	8,
	0
)

DEFINST(V_MUL_LO_U32,
	" v_mul_lo_u32  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	361,
	8,
	0
)

DEFINST(V_MUL_HI_U32,
	" v_mul_hi_u32  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	362,
	8,
	0
)

DEFINST(V_MUL_LO_I32,
	" v_mul_lo_i32  %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	363,
	8,
	0
)

DEFINST(V_DIV_FMAS_F64,
	" v_div_fmas_f64  %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_64_SRC1, %VOP3_64_SRC2",
	VOP3a,
	368,
	8,
	0
)

DEFINST(V_TRIG_PREOP_F64,
	" v_trig_preop_f64  FIXME",
	VOP3a,
	372,
	8,
	0
)

DEFINST(V_FRACT_F32_VOP3a,
	" v_fract_f32   %VOP3_VDST, %VOP3_SRC0",
	VOP3a,
	416,
	8,
	0
)

DEFINST(V_CMP_LT_F32_VOP3a,
	" v_cmp_lt_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	1,
	8,
	0
)

DEFINST(V_CMP_EQ_F32_VOP3a,
	" v_cmp_eq_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	2,
	8,
	0
)

DEFINST(V_CMP_LE_F32_VOP3a,
	" v_cmp_le_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	3,
	8,
	0
)

DEFINST(V_CMP_GT_F32_VOP3a,
	" v_cmp_gt_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	4,
	8,
	0
)

DEFINST(V_CMP_NLE_F32_VOP3a,
	" v_cmp_nle_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	12,
	8,
	0
)


DEFINST(V_CMP_NEQ_F32_VOP3a,
	" v_cmp_neq_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	13,
	8,
	0
)

DEFINST(V_CMP_NLT_F32_VOP3a,
	" v_cmp_nlt_f32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	14,
	8,
	0
)

DEFINST(V_CMP_OP16_F64_VOP3a,
	" v_cmp_%VOP3_OP16_f64  %VOP3_64_SVDST, %VOP3_64_SRC0, %VOP3_64_SRC1",
	VOP3a,
	32,
	8,
	SI_INST_FLAG_OP16
)

DEFINST(V_CMP_LT_I32_VOP3a,
	" v_cmp_lt_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	129,
	8,
	0
)

DEFINST(V_CMP_EQ_I32_VOP3a,
	" v_cmp_eq_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	130,
	8,
	0
)

DEFINST(V_CMP_LE_I32_VOP3a,
	" v_cmp_le_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	131,
	8,
	0
)

DEFINST(V_CMP_GT_I32_VOP3a,
	" v_cmp_gt_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	132,
	8,
	0
)

DEFINST(V_CMP_NE_I32_VOP3a,
	" v_cmp_ne_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	133,
	8,
	0
)

DEFINST(V_CMP_GE_I32_VOP3a,
	" v_cmp_ge_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	134,
	8,
	0
)

DEFINST(V_CMPX_EQ_I32_VOP3a,
	" v_cmpx_eq_i32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	146,
	8,
	0
)

DEFINST(V_CMP_CLASS_F64_VOP3a,
	" v_cmp_class_f64  %VOP3_64_SVDST, %VOP3_64_SRC0, %VOP3_64_SRC1",
	VOP3a,
	168,
	8,
	0
)

DEFINST(V_CMP_LT_U32_VOP3a,
	" v_cmp_lt_u32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	193,
	8,
	0
)

DEFINST(V_CMP_LE_U32_VOP3a,
	" v_cmp_le_u32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	195,
	8,
	0
)

DEFINST(V_CMP_GT_U32_VOP3a,
	" v_cmp_gt_u32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	196,
	8,
	0
)

DEFINST(V_CMP_LG_U32_VOP3a,
	" v_cmp_lg_u32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	197,
	8,
	0
)

DEFINST(V_CMP_GE_U32_VOP3a,
	" v_cmp_ge_u32  %VOP3_64_SVDST, %VOP3_SRC0, %VOP3_SRC1",
	VOP3a,
	198,
	8,
	0
)

DEFINST(V_CMP_LT_U64_VOP3a,
	" v_cmp_lt_u64  %VOP3_64_SVDST, %VOP3_64_SRC0, %VOP3_64_SRC1",
	VOP3a,
	225,
	8,
	0
)

DEFINST(V_MED3_I32,
	" v_med3_i32    %VOP3_VDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_SRC2",
	VOP3a,
	344,
	8,
	0
)

DEFINST(V_LSHR_B64,
	" v_lshr_b64    %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_SRC1",
	VOP3a,
	354,
	8,
	0
)

DEFINST(V_ADD_F64,
	" v_add_f64     %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_64_SRC1",
	VOP3a,
	356,
	8,
	0
)

DEFINST(V_MUL_F64,
	" v_mul_f64     %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_64_SRC1",
	VOP3a,
	357,
	8,
	0
)

DEFINST(V_LDEXP_F64,
	" v_ldexp_f64   %VOP3_64_VDST, %VOP3_64_SRC0, %VOP3_SRC1",
	VOP3a,
	360,
	8,
	0
)

/*
 * VOP3b 
 */

DEFINST(V_ADDC_U32_VOP3b,
	" v_addc_u32    %VOP3_VDST, %VOP3_64_SDST, %VOP3_SRC0, %VOP3_SRC1, %VOP3_64_SRC2",
	VOP3b,
	296,
	8,
	0
)

DEFINST(V_DIV_SCALE_F64,
	" v_div_scale_f64  %VOP3_64_VDST, %VOP3_64_SDST, %VOP3_64_SRC0, %VOP3_64_SRC1, %VOP3_64_SRC2",
	VOP3b,
	366,
	8,
	0
)

/*
 * VINTRP
 */

DEFINST(V_INTERP_P1_F32,
	" v_interp_p1_f32    %VINTRP_VDST, %VSRC_I_J, %ATTR, %ATTRCHAN",
	VINTRP,
	0,
	4,
	0
)

DEFINST(V_INTERP_P2_F32,
	" v_interp_p2_f32    %VINTRP_VDST, %VSRC_I_J, %ATTR, %ATTRCHAN",
	VINTRP,
	1,
	4,
	0
)

DEFINST(V_INTERP_MOV_F32,
	" v_interp_mov_f32    %VINTRP_VDST, %VSRC_I_J, %ATTR, %ATTRCHAN",
	VINTRP,
	2,
	4,
	0
)

/*
 * DS
 */

DEFINST(DS_INC_U32,
	" ds_inc_u32    %ADDR, %DATA0",
	DS,
	3,
	8,
	0
)

DEFINST(DS_WRITE_B32,
	" ds_write_b32  %ADDR, %DATA0",
	DS,
	13,
	8,
	0
)

DEFINST(DS_WRITE2_B32,
	" ds_write2_b32  %ADDR, %DATA0, %DATA1 %OFFSET0%OFFSET1",
	DS,
	14,
	8,
	0
)

DEFINST(DS_WRITE_B8,
	" ds_write_b8   %ADDR, %DATA0",
	DS,
	30,
	8,
	0
)

DEFINST(DS_WRITE_B16,
	" ds_write_b16  %ADDR, %DATA0",
	DS,
	31,
	8,
	0
)

DEFINST(DS_READ_B32,
	" ds_read_b32   %DS_VDST, %ADDR",
	DS,
	54,
	8,
	0
)

DEFINST(DS_READ2_B32,
	" ds_read2_b32  %DS_SERIES_VDST, %ADDR %OFFSET0%OFFSET1",
	DS,
	55,
	8,
	0
)

DEFINST(DS_READ_I8,
	" ds_read_i8    %DS_VDST, %ADDR",
	DS,
	57,
	8,
	0
)

DEFINST(DS_READ_U8,
	" ds_read_u8    %DS_VDST, %ADDR",
	DS,
	58,
	8,
	0
)

DEFINST(DS_READ_I16,
	" ds_read_i16   %DS_VDST, %ADDR",
	DS,
	59,
	8,
	0
)

DEFINST(DS_READ_U16,
	" ds_read_u16   %DS_VDST, %ADDR",
	DS,
	60,
	8,
	0
)

/*
 * MUBUF
 */

DEFINST(BUFFER_LOAD_SBYTE,
	" buffer_load_sbyte  %MU_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MU_MADDR",
	MUBUF,
	9,
	8,
	0
)

DEFINST(BUFFER_LOAD_DWORD,
	" buffer_load_dword  %MU_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MU_MADDR",
	MUBUF,
	12,
	8,
	0
)

DEFINST(BUFFER_STORE_BYTE,
	" buffer_store_byte  %MU_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MU_MADDR %MU_GLC",
	MUBUF,
	24,
	8,
	0
)

DEFINST(BUFFER_STORE_DWORD,
	" buffer_store_dword  %MU_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MU_MADDR %MU_GLC",
	MUBUF,
	28,
	8,
	0
)

DEFINST(BUFFER_ATOMIC_ADD,
	" buffer_atomic_add  %MU_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MU_MADDR",
	MUBUF,
	50,
	8,
	0
)

/*
 * MTBUF
 */

DEFINST(TBUFFER_LOAD_FORMAT_X,
	" tbuffer_load_format_x  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	0,
	8,
	0
)

DEFINST(TBUFFER_LOAD_FORMAT_XY,
	" tbuffer_load_format_xy  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	1,
	8,
	0
)

DEFINST(TBUFFER_LOAD_FORMAT_XYZW,
	" tbuffer_load_format_xyzw  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	3,
	8,
	0
)

DEFINST(TBUFFER_STORE_FORMAT_X,
	" tbuffer_store_format_x  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	4,
	8,
	0
)

DEFINST(TBUFFER_STORE_FORMAT_XY,
	" tbuffer_store_format_xy  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	5,
	8,
	0
)

DEFINST(TBUFFER_STORE_FORMAT_XYZW,
	" tbuffer_store_format_xyzw  %MT_SERIES_VDATA, %VADDR, %SERIES_SRSRC, %MT_MADDR",
	MTBUF,
	7,
	8,
	0
)

/*
 * MIMG
 */

DEFINST(IMAGE_STORE,
	" image_store   %MIMG_SERIES_VDATA, %MIMG_VADDR, %MIMG_DUG_SERIES_SRSRC",
	MIMG,
	8,
	8,
	0
)

DEFINST(IMAGE_SAMPLE,
	" image_sample  %MIMG_SERIES_VDATA, %MIMG_VADDR, %MIMG_SERIES_SRSRC, %MIMG_DUG_SERIES_SSAMP",
	MIMG,
	32,
	8,
	0
)

/* 
 * EXP
 */

DEFINST(EXPORT,
	" export  %TGT, %EXP_VSRCs",
	EXP,
	0,
	8,
	0
)
