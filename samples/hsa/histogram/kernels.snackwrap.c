/* THIS TEMPORARY c SOURCE FILE WAS GENERATED BY snack version 0.9.6 */
/* THIS FILE : /home/yifan/Documents/hsa/multi2sim/samples/hsa/histogram/kernels.snackwrap.c  */
/* INPUT FILE: /home/yifan/Documents/hsa/multi2sim/samples/hsa/histogram/kernels.cl  */
/* UPDATED CL: /tmp/snk_12935/updated.cl  */
/*                               */ 
    
/*

  Copyright (c) 2015 ADVANCED MICRO DEVICES, INC.  

  AMD is granting you permission to use this software and documentation (if any) (collectively, the 
  Materials) pursuant to the terms and conditions of the Software License Agreement included with the 
  Materials.  If you do not have a copy of the Software License Agreement, contact your AMD 
  representative for a copy.

  You agree that you will not reverse engineer or decompile the Materials, in whole or in part, except for 
  example code which is provided in source code form and as allowed by applicable law.

  WARRANTY DISCLAIMER: THE SOFTWARE IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY 
  KIND.  AMD DISCLAIMS ALL WARRANTIES, EXPRESS, IMPLIED, OR STATUTORY, INCLUDING BUT NOT 
  LIMITED TO THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR 
  PURPOSE, TITLE, NON-INFRINGEMENT, THAT THE SOFTWARE WILL RUN UNINTERRUPTED OR ERROR-
  FREE OR WARRANTIES ARISING FROM CUSTOM OF TRADE OR COURSE OF USAGE.  THE ENTIRE RISK 
  ASSOCIATED WITH THE USE OF THE SOFTWARE IS ASSUMED BY YOU.  Some jurisdictions do not 
  allow the exclusion of implied warranties, so the above exclusion may not apply to You. 

  LIMITATION OF LIABILITY AND INDEMNIFICATION:  AMD AND ITS LICENSORS WILL NOT, 
  UNDER ANY CIRCUMSTANCES BE LIABLE TO YOU FOR ANY PUNITIVE, DIRECT, INCIDENTAL, 
  INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING FROM USE OF THE SOFTWARE OR THIS 
  AGREEMENT EVEN IF AMD AND ITS LICENSORS HAVE BEEN ADVISED OF THE POSSIBILITY OF SUCH 
  DAMAGES.  In no event shall AMD's total liability to You for all damages, losses, and 
  causes of action (whether in contract, tort (including negligence) or otherwise) 
  exceed the amount of $100 USD.  You agree to defend, indemnify and hold harmless 
  AMD and its licensors, and any of their directors, officers, employees, affiliates or 
  agents from and against any and all loss, damage, liability and other expenses 
  (including reasonable attorneys' fees), resulting from Your use of the Software or 
  violation of the terms and conditions of this Agreement.  

  U.S. GOVERNMENT RESTRICTED RIGHTS: The Materials are provided with "RESTRICTED RIGHTS." 
  Use, duplication, or disclosure by the Government is subject to the restrictions as set 
  forth in FAR 52.227-14 and DFAR252.227-7013, et seq., or its successor.  Use of the 
  Materials by the Government constitutes acknowledgement of AMD's proprietary rights in them.

  EXPORT RESTRICTIONS: The Materials may be subject to export restrictions as stated in the 
  Software License Agreement.

*/ 

#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <stddef.h>
#include <string.h>
#include "hsa.h"
#include "hsa_ext_finalize.h"

/*  set NOTCOHERENT needs this include
#include "hsa_ext_amd.h"
*/

typedef enum status_t status_t;
enum status_t {
    STATUS_SUCCESS=0,
    STATUS_UNKNOWN=1
};
#ifdef __cplusplus
#define _CPPSTRING_ "C" 
#endif
#ifndef __cplusplus
#define _CPPSTRING_ 
#endif
#ifndef __SNK_DEFS
#define SNK_MAX_STREAMS 8 
extern _CPPSTRING_ void stream_sync(const int stream_num);

#define SNK_ORDERED 1
#define SNK_UNORDERED 0

#include <stdint.h>
#ifndef HSA_RUNTIME_INC_HSA_H_
typedef struct hsa_signal_s { uint64_t handle; } hsa_signal_t;
#endif

typedef struct snk_task_s snk_task_t;
struct snk_task_s { 
   hsa_signal_t signal ; 
   snk_task_t* next;
};

typedef struct snk_lparm_s snk_lparm_t;
struct snk_lparm_s { 
   int ndim;                  /* default = 1 */
   size_t gdims[3];           /* NUMBER OF THREADS TO EXECUTE MUST BE SPECIFIED */ 
   size_t ldims[3];           /* Default = {64} , e.g. 1 of 8 CU on Kaveri */
   int stream;                /* default = -1 , synchrnous */
   int barrier;               /* default = SNK_UNORDERED */
   int acquire_fence_scope;   /* default = 2 */
   int release_fence_scope;   /* default = 2 */
} ;

/* This string macro is used to declare launch parameters set default values  */
#define SNK_INIT_LPARM(X,Y) snk_lparm_t * X ; snk_lparm_t  _ ## X ={.ndim=1,.gdims={Y},.ldims={64},.stream=-1,.barrier=SNK_UNORDERED,.acquire_fence_scope=2,.release_fence_scope=2} ; X = &_ ## X ;
 
/* Equivalent host data types for kernel data types */
typedef struct snk_image3d_s snk_image3d_t;
struct snk_image3d_s { 
   unsigned int channel_order; 
   unsigned int channel_data_type; 
   size_t width, height, depth;
   size_t row_pitch, slice_pitch;
   size_t element_size;
   void *data;
};

#define __SNK_DEFS
#endif

#define ErrorCheck(msg, status) \
if (status != HSA_STATUS_SUCCESS) { \
    printf("%s failed.\n", #msg); \
    exit(1); \
} else { \
 /*  printf("%s succeeded.\n", #msg);*/ \
}

/* Determines if the given agent is of type HSA_DEVICE_TYPE_GPU
   and sets the value of data to the agent handle if it is.
*/
static hsa_status_t get_gpu_agent(hsa_agent_t agent, void *data) {
    hsa_status_t status;
    hsa_device_type_t device_type;
    status = hsa_agent_get_info(agent, HSA_AGENT_INFO_DEVICE, &device_type);
    if (HSA_STATUS_SUCCESS == status && HSA_DEVICE_TYPE_GPU == device_type) {
        hsa_agent_t* ret = (hsa_agent_t*)data;
        *ret = agent;
        return HSA_STATUS_INFO_BREAK;
    }
    return HSA_STATUS_SUCCESS;
}

/* Determines if a memory region can be used for kernarg allocations.  */
static hsa_status_t get_kernarg_memory_region(hsa_region_t region, void* data) {
    hsa_region_segment_t segment;
    hsa_region_get_info(region, HSA_REGION_INFO_SEGMENT, &segment);
    if (HSA_REGION_SEGMENT_GLOBAL != segment) {
        return HSA_STATUS_SUCCESS;
    }

    hsa_region_global_flag_t flags;
    hsa_region_get_info(region, HSA_REGION_INFO_GLOBAL_FLAGS, &flags);
    if (flags & HSA_REGION_GLOBAL_FLAG_KERNARG) {
        hsa_region_t* ret = (hsa_region_t*) data;
        *ret = region;
        return HSA_STATUS_INFO_BREAK;
    }

    return HSA_STATUS_SUCCESS;
}

/* Stream specific globals */
hsa_queue_t* Stream_CommandQ[SNK_MAX_STREAMS];
static int          SNK_NextTaskId = 0 ;

/* Context(cl file) specific globals */
hsa_agent_t                      _kernels_Agent;
hsa_ext_program_t                _kernels_HsaProgram;
hsa_executable_t                 _kernels_Executable;
hsa_region_t                     _kernels_KernargRegion;
int                              _kernels_FC = 0; 

/* Global variables */
hsa_queue_t*                     Sync_CommandQ;
hsa_signal_t                     Sync_Signal; 
#include "kernels_brig.h" 

status_t _kernels_InitContext(){

    hsa_status_t err;

    err = hsa_init();
    ErrorCheck(Initializing the hsa runtime, err);

    /* Iterate over the agents and pick the gpu agent */
    err = hsa_iterate_agents(get_gpu_agent, &_kernels_Agent);
    if(err == HSA_STATUS_INFO_BREAK) { err = HSA_STATUS_SUCCESS; }
    ErrorCheck(Getting a gpu agent, err);

    /* Query the name of the agent.  */
    char name[64] = { 0 };
    err = hsa_agent_get_info(_kernels_Agent, HSA_AGENT_INFO_NAME, name);
    ErrorCheck(Querying the agent name, err);
    /* printf("The agent name is %s.\n", name); */

    /* Query the maximum size of the queue.  */
    uint32_t queue_size = 0;
    err = hsa_agent_get_info(_kernels_Agent, HSA_AGENT_INFO_QUEUE_MAX_SIZE, &queue_size);
    ErrorCheck(Querying the agent maximum queue size, err);
    /* printf("The maximum queue size is %u.\n", (unsigned int) queue_size);  */

    /* Create hsa program.  */
    memset(&_kernels_HsaProgram,0,sizeof(hsa_ext_program_t));
    err = hsa_ext_program_create(HSA_MACHINE_MODEL_LARGE, HSA_PROFILE_FULL, HSA_DEFAULT_FLOAT_ROUNDING_MODE_DEFAULT, NULL, &_kernels_HsaProgram);
    ErrorCheck(Create the program, err);

    /* Add the BRIG module to hsa program.  */
    err = hsa_ext_program_add_module(_kernels_HsaProgram, (hsa_ext_module_t) _kernels_HSA_BrigMem );
    ErrorCheck(Adding the brig module to the program, err);

    /* Determine the agents ISA.  */
    hsa_isa_t isa;
    err = hsa_agent_get_info(_kernels_Agent, HSA_AGENT_INFO_ISA, &isa);
    ErrorCheck(Query the agents isa, err);

    /* * Finalize the program and extract the code object.  */
    hsa_ext_control_directives_t control_directives;
    memset(&control_directives, 0, sizeof(hsa_ext_control_directives_t));
    hsa_code_object_t code_object;
    err = hsa_ext_program_finalize(_kernels_HsaProgram, isa, 0, control_directives,"", HSA_CODE_OBJECT_TYPE_PROGRAM, &code_object);
    ErrorCheck(Finalizing the program, err);

    /* Destroy the program, it is no longer needed.  */
    err=hsa_ext_program_destroy(_kernels_HsaProgram);
    ErrorCheck(Destroying the program, err);

    /* Create the empty executable.  */
    err = hsa_executable_create(HSA_PROFILE_FULL, HSA_EXECUTABLE_STATE_UNFROZEN, "", &_kernels_Executable);
    ErrorCheck(Create the executable, err);

    /* Load the code object.  */
    err = hsa_executable_load_code_object(_kernels_Executable, _kernels_Agent, code_object, "");
    ErrorCheck(Loading the code object, err);

    /* Freeze the executable; it can now be queried for symbols.  */
    err = hsa_executable_freeze(_kernels_Executable, "");
    ErrorCheck(Freeze the executable, err);

    /* Find a memory region that supports kernel arguments.  */
    _kernels_KernargRegion.handle=(uint64_t)-1;
    hsa_agent_iterate_regions(_kernels_Agent, get_kernarg_memory_region, &_kernels_KernargRegion);
    err = (_kernels_KernargRegion.handle == (uint64_t)-1) ? HSA_STATUS_ERROR : HSA_STATUS_SUCCESS;
    ErrorCheck(Finding a kernarg memory region, err);

    /*  Create a queue using the maximum size.  */
    err = hsa_queue_create(_kernels_Agent, queue_size, HSA_QUEUE_TYPE_SINGLE, NULL, NULL, UINT32_MAX, UINT32_MAX, &Sync_CommandQ);
    ErrorCheck(Creating the queue, err);

    /*  Create signal to wait for the dispatch to finish. this Signal is only used for synchronous execution  */ 
    err=hsa_signal_create(1, 0, NULL, &Sync_Signal);
    ErrorCheck(Creating a HSA signal, err);

    /* Create queues and signals for each stream. */
    int stream_num;
    for ( stream_num = 0 ; stream_num < SNK_MAX_STREAMS ; stream_num++){
       /* printf("calling queue create for stream %d\n",stream_num); */
       err=hsa_queue_create(_kernels_Agent, queue_size, HSA_QUEUE_TYPE_SINGLE, NULL, NULL, UINT32_MAX, UINT32_MAX, &Stream_CommandQ[stream_num]);
       ErrorCheck(Creating the Stream Command Q, err);
    }

    return STATUS_SUCCESS;
} /* end of _kernels_InitContext */


void packet_store_release(uint32_t* packet, uint16_t header, uint16_t rest){
  __atomic_store_n(packet,header|(rest<<16),__ATOMIC_RELEASE);
}

uint16_t header(hsa_packet_type_t type) {
   uint16_t header = type << HSA_PACKET_HEADER_TYPE;
   header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE;
   header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE;
   return header;
}

void barrier_sync(int stream_num, snk_task_t *dep_task_list) {
    /* This routine will wait for all dependent packets to complete
       irrespective of their queue number. This will put a barrier packet in the
       stream belonging to the current packet. 
     */

    if(stream_num < 0 || dep_task_list == NULL) return; 

    hsa_queue_t *queue = Stream_CommandQ[stream_num];
    int dep_task_count = 0;
    snk_task_t *head = dep_task_list;
    while(head != NULL) {
        dep_task_count++;
        head = head->next;
    }

    /* Keep adding barrier packets in multiples of 5 because that is the maximum signals that 
       the HSA barrier packet can support today
     */
    snk_task_t *tasks = dep_task_list;
    hsa_signal_t signal;
    hsa_signal_create(1, 0, NULL, &signal);
    const int HSA_BARRIER_MAX_DEPENDENT_TASKS = 5;
    /* round up */
    int barrier_pkt_count = (dep_task_count + HSA_BARRIER_MAX_DEPENDENT_TASKS - 1) / HSA_BARRIER_MAX_DEPENDENT_TASKS;
    int barrier_pkt_id = 0;
    for(barrier_pkt_id = 0; barrier_pkt_id < barrier_pkt_count; barrier_pkt_id++) {
        /* Obtain the write index for the command queue for this stream.  */
        uint64_t index = hsa_queue_load_write_index_relaxed(queue);
        const uint32_t queueMask = queue->size - 1;

        /* Define the barrier packet to be at the calculated queue index address.  */
        hsa_barrier_and_packet_t* barrier = &(((hsa_barrier_and_packet_t*)(queue->base_address))[index&queueMask]);
        memset(barrier, 0, sizeof(hsa_barrier_and_packet_t));
        barrier->header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE;
        barrier->header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE;
        barrier->header |= 0 << HSA_PACKET_HEADER_BARRIER;
        barrier->header |= HSA_PACKET_TYPE_BARRIER_AND << HSA_PACKET_HEADER_TYPE; 

        /* populate all dep_signals */
        int dep_signal_id = 0;
        for(dep_signal_id = 0; dep_signal_id < HSA_BARRIER_MAX_DEPENDENT_TASKS; dep_signal_id++) {
            if(tasks != NULL) {
                /* fill out the barrier packet and ring doorbell */
                barrier->dep_signal[dep_signal_id] = tasks->signal; 
                tasks = tasks->next;
            }
        }
        if(tasks == NULL) { 
            /* reached the end of task list */
            barrier->header |= 1 << HSA_PACKET_HEADER_BARRIER;
            barrier->completion_signal = signal;
        }
        /* Increment write index and ring doorbell to dispatch the kernel.  */
        hsa_queue_store_write_index_relaxed(queue, index+1);
        hsa_signal_store_relaxed(queue->doorbell_signal, index);
        //printf("barrier pkt submitted: %d\n", barrier_pkt_id);
    }

    /* Wait on completion signal til kernel is finished.  */
    hsa_signal_wait_acquire(signal, HSA_SIGNAL_CONDITION_LT, 1, UINT64_MAX, HSA_WAIT_STATE_BLOCKED);

    hsa_signal_destroy(signal);
}

extern void stream_sync(int stream_num) {
    /* This is a user-callable function that puts a barrier packet into a queue where
       all former dispatch packets were put on the queue for asynchronous asynchrnous 
       executions. This routine will wait for all packets to complete on this queue.
    */

    hsa_queue_t *queue = Stream_CommandQ[stream_num];

    hsa_signal_t signal;
    hsa_signal_create(1, 0, NULL, &signal);
  
    /* Obtain the write index for the command queue for this stream.  */
    uint64_t index = hsa_queue_load_write_index_relaxed(queue);
    const uint32_t queueMask = queue->size - 1;

    /* Define the barrier packet to be at the calculated queue index address.  */
    hsa_barrier_or_packet_t* barrier = &(((hsa_barrier_or_packet_t*)(queue->base_address))[index&queueMask]);
    memset(barrier, 0, sizeof(hsa_barrier_or_packet_t));
    barrier->header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE;
    barrier->header |= HSA_FENCE_SCOPE_SYSTEM << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE;
    barrier->header |= 1 << HSA_PACKET_HEADER_BARRIER;
    barrier->header |= HSA_PACKET_TYPE_BARRIER_AND << HSA_PACKET_HEADER_TYPE; 
    barrier->completion_signal = signal;

    /* Increment write index and ring doorbell to dispatch the kernel.  */
    hsa_queue_store_write_index_relaxed(queue, index+1);
    hsa_signal_store_relaxed(queue->doorbell_signal, index);

    /* Wait on completion signal til kernel is finished.  */
    hsa_signal_wait_acquire(signal, HSA_SIGNAL_CONDITION_LT, 1, UINT64_MAX, HSA_WAIT_STATE_BLOCKED);

    hsa_signal_destroy(signal);

}  /* End of generated global functions */

/* Kernel specific globals, one set for each kernel  */
hsa_executable_symbol_t          HIST_Symbol;
int                              HIST_FK = 0 ; 
status_t                         HIST_init(const int printStats);
status_t                         HIST_stop();
uint64_t                         HIST_Kernel_Object;
uint32_t                         HIST_Kernarg_Segment_Size; /* May not need to be global */
uint32_t                         HIST_Group_Segment_Size;
uint32_t                         HIST_Private_Segment_Size;

/* ------  Start of SNACK function HIST ------ */ 
extern void HIST(int* input,int* output,int  colors,int  size, const snk_lparm_t * lparm) {
   /* Kernel initialization has to be done before kernel arguments are set/inspected */ 
   if (HIST_FK == 0 ) { 
     status_t status = HIST_init(0); 
     if ( status  != STATUS_SUCCESS ) return; 
     HIST_FK = 1; 
   } 
   /* Allocate the kernel argument buffer from the correct region. */ 
   void* thisKernargAddress; 
   /* HSA 1.0F has a bug that serializes all queue operations when hsa_memory_allocate is used. 
	  Revert back to hsa_memory_allocate once bug is fixed. */ 
   thisKernargAddress = malloc(HIST_Kernarg_Segment_Size); 
   size_t group_base ; 
   group_base  = (size_t) HIST_Group_Segment_Size;
   struct HIST_args_struct {
      uint64_t arg0;
      uint64_t arg1;
      uint64_t arg2;
      uint64_t arg3;
      uint64_t arg4;
      uint64_t arg5;
      int* arg6;
      int* arg7;
      int arg8;
      int arg9;
   } __attribute__ ((aligned (16))) ; 
   struct HIST_args_struct* HIST_args ; 
   /* Setup kernel args */ 
   HIST_args = (struct HIST_args_struct*) thisKernargAddress; 
   HIST_args->arg0=0 ; 
   HIST_args->arg1=0 ; 
   HIST_args->arg2=0 ; 
   HIST_args->arg3=0 ; 
   HIST_args->arg4=0 ; 
   HIST_args->arg5=0 ; 
   HIST_args->arg6 = input ; 
   HIST_args->arg7 = output ; 
   HIST_args->arg8 = colors ; 
   HIST_args->arg9 = size ; 

    /*  Get stream number from launch parameters.       */
    /*  This must be less than SNK_MAX_STREAMS.         */
    /*  If negative, then function call is synchrnous.  */
    int stream_num = lparm->stream;
    if ( stream_num >= SNK_MAX_STREAMS )  {
       printf(" ERROR Stream number %d specified, must be less than %d \n", stream_num, SNK_MAX_STREAMS);
       return; 
    }

    hsa_queue_t* this_Q ;
    if ( stream_num < 0 ) { /*  Sychronous execution */
       this_Q = Sync_CommandQ;
    } else { /* Asynchrnous execution uses one command Q per stream */
       this_Q = Stream_CommandQ[stream_num];
    }

    /*  Obtain the current queue write index. increases with each call to kernel  */
    uint64_t index = hsa_queue_load_write_index_relaxed(this_Q);
    /* printf("DEBUG:Call #%d to kernel \"%s\" \n",(int) index,"HIST");  */

    /* Find the queue index address to write the packet info into.  */
    const uint32_t queueMask = this_Q->size - 1;
    hsa_kernel_dispatch_packet_t* this_aql = &(((hsa_kernel_dispatch_packet_t*)(this_Q->base_address))[index&queueMask]);

    /*  FIXME: We need to check for queue overflow here. */

    if ( stream_num < 0 ) {
       /* Use the global synchrnous signal Sync_Signal */
       this_aql->completion_signal=Sync_Signal;
       hsa_signal_store_relaxed(Sync_Signal,1);
    }

    /*  Process lparm values */
    /*  this_aql.dimensions=(uint16_t) lparm->ndim; */
    this_aql->setup  |= (uint16_t) lparm->ndim << HSA_KERNEL_DISPATCH_PACKET_SETUP_DIMENSIONS;
    this_aql->grid_size_x=lparm->gdims[0];
    this_aql->workgroup_size_x=lparm->ldims[0];
    if (lparm->ndim>1) {
       this_aql->grid_size_y=lparm->gdims[1];
       this_aql->workgroup_size_y=lparm->ldims[1];
    } else {
       this_aql->grid_size_y=1;
       this_aql->workgroup_size_y=1;
    }
    if (lparm->ndim>2) {
       this_aql->grid_size_z=lparm->gdims[2];
       this_aql->workgroup_size_z=lparm->ldims[2];
    } else {
       this_aql->grid_size_z=1;
       this_aql->workgroup_size_z=1;
    }

	/* thisKernargAddress has already been set up in the beginning of this routine */
    /*  Bind kernel argument buffer to the aql packet.  */
    this_aql->kernarg_address = (void*) thisKernargAddress;
    this_aql->kernel_object = HIST_Kernel_Object;
    this_aql->private_segment_size = HIST_Private_Segment_Size;
    this_aql->group_segment_size = group_base; /* group_base includes static and dynamic group space */

    /*  Prepare and set the packet header */ 
    /* Only set barrier bit if asynchrnous execution */
    if ( stream_num >= 0 )  this_aql->header |= lparm->barrier << HSA_PACKET_HEADER_BARRIER; 
    this_aql->header |= lparm->acquire_fence_scope << HSA_PACKET_HEADER_ACQUIRE_FENCE_SCOPE;
    this_aql->header |= lparm->release_fence_scope  << HSA_PACKET_HEADER_RELEASE_FENCE_SCOPE;
    __atomic_store_n((uint8_t*)(&this_aql->header), (uint8_t)HSA_PACKET_TYPE_KERNEL_DISPATCH, __ATOMIC_RELEASE);

    /* Increment write index and ring doorbell to dispatch the kernel.  */
    hsa_queue_store_write_index_relaxed(this_Q, index+1);
    hsa_signal_store_relaxed(this_Q->doorbell_signal, index);

    if ( stream_num < 0 ) {
       /* For default synchrnous execution, wait til kernel is finished.  */
       hsa_signal_value_t value = hsa_signal_wait_acquire(Sync_Signal, HSA_SIGNAL_CONDITION_LT, 1, UINT64_MAX, HSA_WAIT_STATE_BLOCKED);
    }

    /*  *** END OF KERNEL LAUNCH TEMPLATE ***  */
    return;
} 
/* ------  End of SNACK function HIST ------ */ 
#include "amd_kernel_code.h"
extern status_t HIST_init(const int printStats){
    if (_kernels_FC == 0 ) {
       status_t status = _kernels_InitContext();
       if ( status  != STATUS_SUCCESS ) return; 
       _kernels_FC = 1;
    }
   
    hsa_status_t err;

    /* Extract the symbol from the executable.  */
    /* printf("Kernel name HIST_: Looking for symbol %s\n","__OpenCL_HIST_kernel"); */
    err = hsa_executable_get_symbol(_kernels_Executable, NULL, "&__OpenCL_HIST_kernel", _kernels_Agent , 0, &HIST_Symbol);
    ErrorCheck(Extract the symbol from the executable, err);

    /* Extract dispatch information from the symbol */
    err = hsa_executable_symbol_get_info(HIST_Symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_OBJECT, &HIST_Kernel_Object);
    ErrorCheck(Extracting the symbol from the executable, err);
    err = hsa_executable_symbol_get_info(HIST_Symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_KERNARG_SEGMENT_SIZE, &HIST_Kernarg_Segment_Size);
    ErrorCheck(Extracting the kernarg segment size from the executable, err);
    err = hsa_executable_symbol_get_info(HIST_Symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_GROUP_SEGMENT_SIZE, &HIST_Group_Segment_Size);
    ErrorCheck(Extracting the group segment size from the executable, err);
    err = hsa_executable_symbol_get_info(HIST_Symbol, HSA_EXECUTABLE_SYMBOL_INFO_KERNEL_PRIVATE_SEGMENT_SIZE, &HIST_Private_Segment_Size);
    ErrorCheck(Extracting the private segment from the executable, err);

    if (printStats == 1) {
       printf("Post-finalization statistics for kernel: HIST \n" );
       amd_kernel_code_t *akc = (amd_kernel_code_t*) HIST_Kernel_Object;
       printf("   wavefront_sgpr_count: ");
       printf("%u\n", (uint32_t) akc->wavefront_sgpr_count);
       printf("   workitem_vgpr_count: ");
       printf("%u\n", (uint32_t) akc->workitem_vgpr_count);
       printf("   workgroup_fbarrier_count: ");
       printf("%u\n", (uint32_t) akc->workgroup_fbarrier_count);
       printf("   local data store bytes: ");
       printf("%u\n", (uint32_t) HIST_Group_Segment_Size);
       printf("   private store bytes : ");
       printf("%u\n", (uint32_t) HIST_Private_Segment_Size);
       printf("   kernel arguments bytes: ");
       printf("%u\n", (uint32_t) HIST_Kernarg_Segment_Size);
    }

    return STATUS_SUCCESS;

} /* end of HIST_init */


extern status_t HIST_stop(){
    status_t err;
    if (_kernels_FC == 0 ) {
       /* weird, but we cannot stop unless we initialized the context */
       err = _kernels_InitContext();
       if ( err != STATUS_SUCCESS ) return err; 
       _kernels_FC = 1;
    }
    if ( HIST_FK == 1 ) {
        /*  Currently nothing kernel specific must be recovered */
       HIST_FK = 0;
    }
    return STATUS_SUCCESS;

} /* end of HIST_stop */


